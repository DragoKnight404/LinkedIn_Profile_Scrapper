{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LinkedIn Profile Scraper in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Announcement-on-ML\n",
    "<a href='http://www.kgptalkie.com' target=\"_blank\"> <img src='https://github.com/laxmimerit/Important-Announcement-on-ML/raw/master/kgptalkie_strips.png'/></a>\n",
    "\n",
    "# ML Resources\n",
    "|  ML Course | Description |\n",
    "|:---|:---|\n",
    "| [**Fine Tuning LLM with HuggingFace Transformers for NLP**](https://www.udemy.com/course/fine-tuning-llm-with-hugging-face-transformers/?referralCode=6DEB3BE17C2644422D8E) | Learn how to fine tune LLM with custom dataset. You will learn basics of transformers then fine tune LLM|\n",
    "| [**Data Visualization in Python Masterclassâ„¢: Beginners to Pro**](https://bit.ly/udemy95off_kgptalkie) |  Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Python for Machine Learning: A Step-by-Step Guide**](https://bit.ly/ml-ds-project) | Learn to build Machine Learning and Deep Learning models using Python and its libraries like Scikit-Learn, Keras, and TensorFlow. |\n",
    "| [**Deep Learning for Beginners with Python**](https://bit.ly/dl-with-python) | Neural Networks, TensorFlow, ANN, CNN, RNN, LSTM, Transfer Learning and Much More. |\n",
    "| [**Python for Linear Regression in Machine Learning**](https://bit.ly/regression-python) | Learn to build Linear Regression models using Python and its libraries like Scikit-Learn. |\n",
    "| [**Introduction to Spacy 3 for Natural Language Processing**](https://bit.ly/spacy-intro) | Learn to build Natural Language Processing models using Python and its libraries like Spacy. |\n",
    "| [**Advanced Machine Learning and Deep Learning Projects**](https://bit.ly/kgptalkie_ml_projects) | Learn to build Advanced Machine Learning and Deep Learning models using Python and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Natural Language Processing in Python for Beginners**](https://bit.ly/intro_nlp) | Learn to build Natural Language Processing Projects using Spacy, NLTK, and Gensim, and transformer models like BERT, GPT-2, and XLNet. |\n",
    "| [**Deployment of Machine Learning Models in Production in Python**](https://bit.ly/bert_nlp) |  Learn to deploy Machine Learning and Deep Learning models using Python and its libraries like Flask, Streamlit, and NGINX. |\n",
    "| [**R 4.0 Programming for Data Science - Beginners to Pro**](https://bit.ly/r4-ml) | Learn to build Machine Learning and Deep Learning models using R and its libraries like caret, tidyverse, and keras. |\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YouTube Video: https://youtu.be/SQtwhuYJk3M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 179,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "\n",
    "from time import sleep\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't have a .env file, you can create one and add the following lines:\n",
    "os.environ['EMAIL'] = 'your_email'\n",
    "os.environ['PASSWORD'] = 'your_password'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver = webdriver.Chrome()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.linkedin.com/login')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'LinkedIn Login, Sign in | LinkedIn'"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.title # confirms that screen is on login page"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "email = driver.find_element(By.ID, 'username')\n",
    "email.send_keys(os.environ['EMAIL'])\n",
    "\n",
    "password = driver.find_element(By.ID, 'password')\n",
    "password.send_keys(os.environ['PASSWORD'])\n",
    "\n",
    "password.submit()\n",
    "# now the screen is on https://www.linkedin.com/feed/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "## MAKE SURE TO USE ONLY THIS URL TO AVOID BEING STUCK IN ERRORS\n",
    "\n",
    "#url = \"https://www.linkedin.com/in/laxmimerit\" # profile to scrape\n",
    "url = \"https://www.linkedin.com/in/shubham-karampure/\"\n",
    "driver.get(url)\n",
    "\n",
    "#driver.title\n",
    "if driver.title == 'LinkedIn':\n",
    "  print('Error Please provide a proper linkedin profile url')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data = {}  # here we will store the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'(3) Shubham Karampure | LinkedIn'"
      ]
     },
     "execution_count": 184,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "driver.title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "name =  Laxmi Kant\n"
     ]
    }
   ],
   "source": [
    "page_source = driver.page_source  # gets all the html code\n",
    "soup = BeautifulSoup(page_source, 'lxml') # parse\n",
    "\n",
    "#name = soup.find('h1', {'class': 'lSVmRsHWVyNnNULXTOLIQEQVzhkaazrTFzDYEginline t-24 v-align-middle break-words'}) # class name of user name\n",
    "#name = soup.find('h1', class_=re.compile(r'inline\\s+t-24\\s+v-align-middle\\s+break-words'))\n",
    "name = driver.find_element(By.XPATH, \"//h1[contains(@class, 'inline') and contains(@class, 't-24') and contains(@class, 'v-align-middle')]\").text\n",
    "\n",
    "print('name = ',name)\n",
    "\n",
    "name = name.strip()\n",
    "\n",
    "profile_data['name'] = name\n",
    "profile_data['url'] = url"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Laxmi Kant', 'url': 'https://www.linkedin.com/in/laxmimerit'}"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline = soup.find('div', {'class': 'text-body-medium break-words'})\n",
    "headline = headline.get_text().strip()\n",
    "\n",
    "profile_data['headline'] = headline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Laxmi Kant',\n",
       " 'url': 'https://www.linkedin.com/in/laxmimerit',\n",
       " 'headline': 'Gen AI in Finance & Investment Services | Data Scientist | IIT Kharagpur | Asset Management | AI-Driven Financial Modeling | Search Ranking | NLP Python BERT AWS Elasticsearch GNN SQL LLM | AI in Investment Strategies'}"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Show More"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "sections = soup.find_all('section', {'class': 'artdeco-card pv-profile-card break-words mt2'})  # get all the sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AboutAbout\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Demonstrated 8+ years of expertise in advanced analytics as an AVP in Data Science, showcasing dynamic and impactful contributions. Seeking to leverage expertise in customer behavior modeling, personalized marketing, product discovery & search optimization, and recommendations to drive impactful solutions in the fields of Data Science, Machine Learning, and Artificial Intelligence.ðŸ‘‰ Significant Achievements Across Careerâ–ª Strategically led impactful initiatives in Customer Behavior Modeling, resulting in a substantial 30% increase in customer retention and a 10% reduction in advertising spending.â–ª Pioneered the development and implementation of a Machine Learning product relevance ranking system, contributing to a remarkable 30% increase in conversion rates and a 20% growth in revenue.â–ª Applied innovative techniques, including Social Graph Analytics and Predictive  Modeling, achieving a 35% improvement in recommendation conversion rates and a 40% increase in customer care calling conversion rates.â–ª Revolutionized customer segmentation and ranking, realizing a notable 20% improvement in conversion rates.â–ª Engineered predictive models for email open rates, driving a remarkable 70% improvement in email engagement.â–ª Achieved transformative outcomes, including a substantial 50% improvement in search conversion rates, a notable 60% increase in revenue, and an impressive 90% reduction in zero-result queries.â–ª A strategic driver of user satisfaction and engagement, evidenced by a commendable 10% decrease in exit rates.Demonstrated 8+ years of expertise in advanced analytics as an AVP in Data Science, showcasing dynamic and impactful contributions. Seeking to leverage expertise in customer behavior modeling, personalized marketing, product discovery & search optimization, and recommendations to drive impactful solutions in the fields of Data Science, Machine Learning, and Artificial Intelligence.\n",
      "\n",
      "ðŸ‘‰ Significant Achievements Across Career\n",
      "â–ª Strategically led impactful initiatives in Customer Behavior Modeling, resulting in a substantial 30% increase in customer retention and a 10% reduction in advertising spending.\n",
      "\n",
      "â–ª Pioneered the development and implementation of a Machine Learning product relevance ranking system, contributing to a remarkable 30% increase in conversion rates and a 20% growth in revenue.\n",
      "\n",
      "â–ª Applied innovative techniques, including Social Graph Analytics and Predictive  Modeling, achieving a 35% improvement in recommendation conversion rates and a 40% increase in customer care calling conversion rates.\n",
      "\n",
      "â–ª Revolutionized customer segmentation and ranking, realizing a notable 20% improvement in conversion rates.\n",
      "\n",
      "â–ª Engineered predictive models for email open rates, driving a remarkable 70% improvement in email engagement.\n",
      "\n",
      "â–ª Achieved transformative outcomes, including a substantial 50% improvement in search conversion rates, a notable 60% increase in revenue, and an impressive 90% reduction in zero-result queries.\n",
      "\n",
      "â–ª A strategic driver of user satisfaction and engagement, evidenced by a commendable 10% decrease in exit rates.\n",
      "\n",
      " \n",
      "              â€¦see more\n",
      "            \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Top skillsTop skills\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "SQL â€¢ Machine Learning â€¢ Python â€¢ Amazon Web Services (AWS) â€¢ Large Language Models (LLM)SQL â€¢ Machine Learning â€¢ Python â€¢ Amazon Web Services (AWS) â€¢ Large Language Models (LLM)\n"
     ]
    }
   ],
   "source": [
    "for sec in sections:\n",
    "    if sec.find('div', {'id': 'about'}): \n",
    "        about = sec\n",
    "\n",
    "print(about.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aryan code                           # FOljEKbcIlJbpAsoKuwYMBJWRHAnGBlw\n",
    "about = about.find('div', class_='display-flex ph5 pv3')\n",
    "\n",
    "about = about.get_text().strip()\n",
    "\n",
    "profile_data['about'] = about\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.CLASS_NAME, \"inline-show-more-text__button\").click()  # unneccesary\n",
    "# in the about section if there is a see more button we need to click it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# unnecessary\n",
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "about = soup.find('div', {'class': 'display-flex ph5 pv3'})\n",
    "\n",
    "about = about.get_text().strip()\n",
    "\n",
    "profile_data['about'] = about"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'Laxmi Kant',\n",
       " 'url': 'https://www.linkedin.com/in/laxmimerit',\n",
       " 'headline': 'Gen AI in Finance & Investment Services | Data Scientist | IIT Kharagpur | Asset Management | AI-Driven Financial Modeling | Search Ranking | NLP Python BERT AWS Elasticsearch GNN SQL LLM | AI in Investment Strategies',\n",
       " 'about': 'Demonstrated 8+ years of expertise in advanced analytics as an AVP in Data Science, showcasing dynamic and impactful contributions. Seeking to leverage expertise in customer behavior modeling, personalized marketing, product discovery & search optimization, and recommendations to drive impactful solutions in the fields of Data Science, Machine Learning, and Artificial Intelligence.ðŸ‘‰ Significant Achievements Across Careerâ–ª Strategically led impactful initiatives in Customer Behavior Modeling, resulting in a substantial 30% increase in customer retention and a 10% reduction in advertising spending.â–ª Pioneered the development and implementation of a Machine Learning product relevance ranking system, contributing to a remarkable 30% increase in conversion rates and a 20% growth in revenue.â–ª Applied innovative techniques, including Social Graph Analytics and Predictive  Modeling, achieving a 35% improvement in recommendation conversion rates and a 40% increase in customer care calling conversion rates.â–ª Revolutionized customer segmentation and ranking, realizing a notable 20% improvement in conversion rates.â–ª Engineered predictive models for email open rates, driving a remarkable 70% improvement in email engagement.â–ª Achieved transformative outcomes, including a substantial 50% improvement in search conversion rates, a notable 60% increase in revenue, and an impressive 90% reduction in zero-result queries.â–ª A strategic driver of user satisfaction and engagement, evidenced by a commendable 10% decrease in exit rates.Demonstrated 8+ years of expertise in advanced analytics as an AVP in Data Science, showcasing dynamic and impactful contributions. Seeking to leverage expertise in customer behavior modeling, personalized marketing, product discovery & search optimization, and recommendations to drive impactful solutions in the fields of Data Science, Machine Learning, and Artificial Intelligence.\\n\\nðŸ‘‰ Significant Achievements Across Career\\nâ–ª Strategically led impactful initiatives in Customer Behavior Modeling, resulting in a substantial 30% increase in customer retention and a 10% reduction in advertising spending.\\n\\nâ–ª Pioneered the development and implementation of a Machine Learning product relevance ranking system, contributing to a remarkable 30% increase in conversion rates and a 20% growth in revenue.\\n\\nâ–ª Applied innovative techniques, including Social Graph Analytics and Predictive  Modeling, achieving a 35% improvement in recommendation conversion rates and a 40% increase in customer care calling conversion rates.\\n\\nâ–ª Revolutionized customer segmentation and ranking, realizing a notable 20% improvement in conversion rates.\\n\\nâ–ª Engineered predictive models for email open rates, driving a remarkable 70% improvement in email engagement.\\n\\nâ–ª Achieved transformative outcomes, including a substantial 50% improvement in search conversion rates, a notable 60% increase in revenue, and an impressive 90% reduction in zero-result queries.\\n\\nâ–ª A strategic driver of user satisfaction and engagement, evidenced by a commendable 10% decrease in exit rates.\\n\\n \\n              â€¦see more',\n",
       " 'experience': [{'company_name': 'IGP',\n",
       "   'duration': 'Full-time Â· 4 yrs 10 mos',\n",
       "   'designations': [{'designation': 'Assistant Vice President',\n",
       "     'duration': 'Oct 2023 to Sep 2024 Â· 1 yr',\n",
       "     'location': 'Mumbai, Maharashtra, India',\n",
       "     'projects': 'ðŸ‘‰Customer Behavior Modeling:\\nEstimating Customer Lifetime Value (CLV) predicts customer worth, churn forecasts retention, and purchase propensity gauges transaction counts and spending. Tier transition analysis influences segmentation, retention, and personalized marketing, enhancing satisfaction, loyalty, and revenue.\\n\\nðŸ‘‰Hashtag Search:\\nEnhancing search functionality by integrating product attributes into phrases for a more intuitive and efficient product discovery process.\\n\\nðŸ‘‰Automated Customer Feedback Report:\\nUtilizing fine-tuning of a Large Language Model to generate diverse supervised data, addressing imbalances in actual data for improved analysis and data-driven decision-making in customer satisfaction and issue resolution.\\n\\nðŸ‘‰Meta Tag Generator for PLP, PDP, and Query Pages:\\nThe \"Meta Tag Generator\" project automates meta tag creation for PLP, PDP, and Query Pages, optimizing search engine visibility and attracting targeted traffic to the website.'},\n",
       "    {'designation': 'Associate Vice President',\n",
       "     'duration': 'Apr 2021 to Oct 2023 Â· 2 yrs 7 mos',\n",
       "     'location': 'Mumbai, Maharashtra, India Â· On-site',\n",
       "     'projects': 'ðŸ‘‰Personalized Search:\\nEngineered dynamic product ranking tailored to individual users, optimizing the search experience based on user preferences.\\n\\nðŸ‘‰Graph and Big Data Analysis:\\nDesigned and implemented graph and big-data analysis tools to extract valuable insights, contributing to strategic decision-making.\\n\\nðŸ‘‰Implicit Customer Features Identification:\\nUtilized demographic data, including religion, native region, and gender, to drive targeted marketing, resulting in personalized recommendations and search suggestions aligned with individual preferences.\\n\\nðŸ‘‰Social Graph Analytics for Personalized Search and Recommendation:\\nAnalyzed user social graphs and click journeys to develop sophisticated recommendation systems, providing personalized suggestions based on user behavior and connections.\\n\\nðŸ‘‰Customer Segmentation and Ranking:\\nImplemented techniques to segment customers based on diverse attributes and ranked them according to relevance and potential value, enhancing the personalization of product rankings.\\n\\nðŸ‘‰Image Segmentation and Phrase Generation:\\nApplied image segmentation techniques to enrich e-commerce product attributes and utilized phrase generation to create descriptive and informative content.\\n\\nðŸ‘‰Customer Purchase Intention and Cart Value Prediction:\\nDeveloped models for predicting customer purchase intentions and cart values, contributing to optimized marketing strategies and an improved shopping experience.\\n\\nðŸ‘‰User Category and MRP Affinity:\\nExplored user categories and their affinity towards specific products or price ranges, leveraging insights to enhance personalized recommendations and targeted marketing efforts.\\n\\nðŸ‘‰Social Graph-Based Occasion Marking and Relation Prediction:\\nLeveraged the social graph to identify occasions and predict user relationships, facilitating personalized recommendations aligned with specific events or social connections.'}]},\n",
       "  {'company_name': 'mBreath',\n",
       "   'duration': '3 yrs 4 mos',\n",
       "   'designations': [{'designation': 'Co-Founder',\n",
       "     'duration': 'Aug 2016 to Nov 2019 Â· 3 yrs 4 mos',\n",
       "     'location': 'STEP, IIT Kharagpur',\n",
       "     'projects': 'There are some of the project which I did at mBreath.\\nReal-Time Human Vital Parameter Estimation Using Pressure Sensor and Machine Learning\\nMeasured respiration and heart rate through an array of pressure sensors and Deep Learning (CNN, RNN-LSTM) algorithms. [Filed Patent Ref No. 201731038573]. 96% accuracy was achieved. The project had three stages 1) preprocessing with analog filters, 2) Digital Signal Processing, 3) Machine Learning model thereafter data is uploaded to the cloud for further processing.\\n\\nReal-time Classification of Environmental Sounds & Their Impacts on Sleep Quality\\nCollected audio using a microphone and Qualcommâ€™s Snapdragon processor enabled custom-built board running Android 6.0. Audio Cleaning, Feature Extraction (more than 700 features) in Temporal, Spectral, Energy, Harmonic, and Cepstral domain, Feature Selection for faster training and better accuracy and ML models (CNN, LSTM, RF, SVM) are designed to classify snoring and other sound and their impact on sleep quality.\\n\\nA Real-Time System and Methods for the Detection of Sleep Apnea and Sleep Stage\\nUsed CNN, Inception, LSTM, CNN-LSTM models to estimate Sleep Apnea and Sleep Stages using the respiration signal only. The training data was obtained from MESA, National Sleep Research Resource, USA. I did data cleaning and balancing thereafter feature engineering and selection were done before applying the ML model. Achieved 82.7% accuracy in Sleep Apnea which is higher than any known methods applied on respiration signal in MESA Dataset and achieved more than 80% accuracy in sleep stage classification which can be considered as good accuracy.\\n\\nVisit:\\nhttp://www.sleepdoc.ai\\nhttp://www.facebook.com/mBreathOfficial\\nhttp://www.twitter.com/mBreathOfficial'}]},\n",
       "  {'company_name': 'Indian Institute of Technology, Kharagpur',\n",
       "   'duration': '4 yrs 8 mos',\n",
       "   'designations': [{'designation': 'Student',\n",
       "     'duration': 'Jul 2012 to Feb 2017 Â· 4 yrs 8 mos',\n",
       "     'location': 'Kharagpur, India',\n",
       "     'projects': ''},\n",
       "    {'designation': 'Teacher Assistant',\n",
       "     'duration': 'Jan 2013 to Jan 2017 Â· 4 yrs 1 mo',\n",
       "     'location': 'IIT Kharagpur',\n",
       "     'projects': 'It was a great experience to teach Embedded Systems. The objective of the teaching is the implementation of the adaptive filter on embedded hardware and software.\\nImplementation of the DSP algorithms was done in Assembly language. Students get comprehensive knowledge of Embedded System and IoT.'}]}],\n",
       " 'projects': [{'project_name': 'Smart Sleep Sense: An Unobtrusive and IoT Enabled Wireless Sleep Monitoring System',\n",
       "   'duration': 'May 2015 - Present',\n",
       "   'description': 'The project aims at developing a portable Human monitoring device that detects the health parameters (heart pulse, breathing rate, thermal emotion recognition, awakening at REM stage of the sleep) and communicates the signals obtained from sensors to the Android app via Wireless network. The information is used to convey Smart Assistance to the user for their daily improved health care conditions thus improving their efficiency and longevity. We are offering sleep disorder monitoring devices. In addition to this, our business model is B2C and device will be directly available to the customer for purchase via online e-commerce stores as well as company e-store itself and the expected cost will be in between 110 to 149 dollar.'},\n",
       "  {'project_name': 'Optimized Fixed Point Kalman Filter Implementation on Embedded Hardware',\n",
       "   'duration': 'Aug 2013 - Apr 2014',\n",
       "   'description': 'Real time adaptive signal processing is an area of considerable interest for the researchers in the field of embedded signal processing. Owing to the large dynamic range and constant relative accuracy of floating point arithmetic, filters are traditionally realized in floating point data type. However, using floating point arithmetic in embedded systems lead to larger cost in terms of latency, power and memory. Therefore these algorithms need to be implemented in fixed point for optimizing these constraints. However with the reduction in the word length the precision get affected. Therefore these algorithms need to be coded properly with adequate fixed point format such that precision is not affected while the resources are optimized. In this thesis an attempt has been made to implement Least Mean Square (LMS), Recursive Least Square (RLS) and Kalman Filtering algorithms on ARM Cortex M0+ with Thumb instruction set. The word length has been optimized for accurate performance, reduced power, improved speed and reduced memory usage. The validation of the algorithm has been carried out with respect to MATLAB.'},\n",
       "  {'project_name': 'MIPS64 5-stages Processor Designing',\n",
       "   'duration': 'Jan 2013 - May 2013',\n",
       "   'description': 'The machine was designed with the MIPS instruction set in mind. Its purpose was to be able to take  a  binary  representation  of  a  MIPS  instruction  and  convert  it  into  microcode.    The microcode controls the actions of the processor and pipeline. Pipelining is a process of multitasking instructions in the same data path.  An instruction can be loaded into the data path at every clock cycle, even though each instruction takes up to 5 cycles to complete.  At every clock cycle, each instruction is stored into a different stage in the pipeline. Doing this does not affect any of the other instructions in the processor because they are in different stages. Each stage  contains  a  different  part  of  the  data  path  and  has  a specific function. This allows the user of the processor to fully utilize all components of the data path simultaneously, causing an increase in the throughput of their program.'},\n",
       "  {'project_name': 'Transistor Characteristics Curve Tracer',\n",
       "   'duration': 'Feb 2012 - May 2013',\n",
       "   'description': 'A cost effective and reliable curve tracer has been designed and developed for NPN- PNP transistors using AT89C51 microcontroller. The system plots desired number of transfer and static characteristics curves on a given range of constant biasing parameter viz; VCE and IB resp. The system plots these characteristics curves of the given transistor on the available computer system through the developed software on Visual BASIC 6.0.  h-parameters of the transistor have also been obtained for different design requirement. All the data has also been stored in a user defined output file for further analysis.'},\n",
       "  {'project_name': 'Automated BJT Curve Tracer using Visual Basic',\n",
       "   'duration': 'Jan 2012 - May 2012',\n",
       "   'description': 'The characteristic of any discrete component plays an important role for determining its behavior for different applications. In this paper we have developed a cost effective BJT curve tracer and binning system which consist of hardware part that is implemented using 89c51 microcontroller and software part which is developed in Microsoft Visual Basic 6.0. This complete system plots the input characteristics curves, h-parameters of the given transistor along with other parameters i.e. C-E resistance and early voltage. Binning machine is used to find the working mode of BJT and to find whether the BJT is working or not by using the port given on the hardware. All the data can also be stored in a user defined output file in the computer for further analysis. This tracer and binning machine can be used for educational and engineering purposes.'}]}"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Read Experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "sections = soup.find_all('section', {'class': 'artdeco-card pv-profile-card break-words mt2'})  # get all the sections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ExperienceExperience\n",
      "\n",
      " \n",
      " \n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Chief Executive OfficerChief Executive Officer\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "SP-TBI Â· Full-timeSP-TBI Â· Full-time\n",
      "\n",
      "\n",
      "Jun 2024 - Present Â· 7 mosJun 2024 to Present Â· 7 mos\n",
      "\n",
      "\n",
      "Mumbai, Maharashtra, India Â· On-siteMumbai, Maharashtra, India Â· On-site\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Professor of PracticeProfessor of Practice\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Bhartiya Vidya Bhavans Sardar Patel Institute of Technology Munshi Nagar Andheri Mumbai Â· Part-timeBhartiya Vidya Bhavans Sardar Patel Institute of Technology Munshi Nagar Andheri Mumbai Â· Part-time\n",
      "\n",
      "\n",
      "Aug 2023 - Present Â· 1 yr 5 mosAug 2023 to Present Â· 1 yr 5 mos\n",
      "\n",
      "\n",
      "Mumbai, Maharashtra, India Â· On-siteMumbai, Maharashtra, India Â· On-site\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Software Development, Algorithms and +6 skills\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "FounderFounder\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Productivity stealth startup Â· Self-employedProductivity stealth startup Â· Self-employed\n",
      "\n",
      "\n",
      "Apr 2023 - Present Â· 1 yr 9 mosApr 2023 to Present Â· 1 yr 9 mos\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Building in the space of productivityBuilding in the space of productivity\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Lead Machine Learning EngineerLead Machine Learning Engineer\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "NNext Â· Full-timeNNext Â· Full-time\n",
      "\n",
      "\n",
      "Nov 2022 - Feb 2023 Â· 4 mosNov 2022 to Feb 2023 Â· 4 mos\n",
      "\n",
      "\n",
      "United StatesUnited States\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Data ScientistData Scientist\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "Collective[i]Collective[i]\n",
      "\n",
      "\n",
      "Nov 2016 - Apr 2022 Â· 5 yrs 6 mosNov 2016 to Apr 2022 Â· 5 yrs 6 mos\n",
      "\n",
      "\n",
      "Greater New York City AreaGreater New York City Area\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Git, Software Development and +5 skills\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      " \n",
      "              Show all 10 experiences\n"
     ]
    }
   ],
   "source": [
    "for sec in sections:\n",
    "    if sec.find('div', {'id': 'experience'}):  # find the experience section\n",
    "        experience = sec\n",
    "\n",
    "print(experience.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [],
   "source": [
    "experience = experience.find_all('div', {'class': 'fPLNkfiTqBJivqMiXLaRuObcmlUMZsDPkIAVk SeRILEEOfWLelfcuceiLywOjAamlMoEkmnTdFk itGgYIXPpfAaqNrUDXHQVkGSUXMzldwQtdzM'})\n",
    "# find all divs from experience"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 228,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(experience) # means experience in 3 places"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "exp = experience[0]   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<div class=\"fPLNkfiTqBJivqMiXLaRuObcmlUMZsDPkIAVk SeRILEEOfWLelfcuceiLywOjAamlMoEkmnTdFk itGgYIXPpfAaqNrUDXHQVkGSUXMzldwQtdzM\" data-view-name=\"profile-component-entity\">\n",
       "<div>\n",
       "<a class=\"optional-action-target-wrapper display-flex\" data-field=\"experience_company_logo\" href=\"https://www.linkedin.com/company/2412659/\" target=\"_self\">\n",
       "<div class=\"ivm-image-view-model pvs-entity__image\">\n",
       "<div class=\"ivm-view-attr__img-wrapper\">\n",
       "<!-- -->\n",
       "<!-- --> <img alt=\"Collective[i] logo\" class=\"ivm-view-attr__img--centered EntityPhoto-square-3 evi-image lazy-image ember-view\" height=\"48\" id=\"ember103\" loading=\"lazy\" src=\"https://media.licdn.com/dms/image/v2/D560BAQG1wEU0SSGUVQ/company-logo_100_100/company-logo_100_100/0/1720398339018/collective_i__logo?e=1741824000&amp;v=beta&amp;t=ZyxQTXPQRTDthP1SL50k7dM_codK9OZuD2x1YX0q-ng\" width=\"48\"/>\n",
       "</div>\n",
       "</div>\n",
       "</a>\n",
       "</div>\n",
       "<div class=\"display-flex flex-column align-self-center flex-grow-1\">\n",
       "<div class=\"display-flex flex-row justify-space-between\">\n",
       "<div class=\"display-flex flex-column full-width\">\n",
       "<div class=\"display-flex flex-wrap align-items-center full-height\">\n",
       "<div class=\"display-flex\">\n",
       "<div class=\"display-flex full-width\">\n",
       "<div class=\"display-flex align-items-center mr1 t-bold\">\n",
       "<span aria-hidden=\"true\"><!-- -->Data Scientist<!-- --></span><span class=\"visually-hidden\"><!-- -->Data Scientist<!-- --></span>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "<!-- --><!-- --><!-- --> </div>\n",
       "<span class=\"t-14 t-normal\">\n",
       "<span aria-hidden=\"true\"><!-- -->Collective[i]<!-- --></span><span class=\"visually-hidden\"><!-- -->Collective[i]<!-- --></span>\n",
       "</span>\n",
       "<span class=\"t-14 t-normal t-black--light\">\n",
       "<span aria-hidden=\"true\" class=\"pvs-entity__caption-wrapper\"><!-- -->Nov 2016 - Apr 2022 Â· 5 yrs 6 mos<!-- --></span><span class=\"visually-hidden\"><!-- -->Nov 2016 to Apr 2022 Â· 5 yrs 6 mos<!-- --></span>\n",
       "</span>\n",
       "<span class=\"t-14 t-normal t-black--light\">\n",
       "<span aria-hidden=\"true\"><!-- -->Greater New York City Area<!-- --></span><span class=\"visually-hidden\"><!-- -->Greater New York City Area<!-- --></span>\n",
       "</span>\n",
       "</div>\n",
       "</div>\n",
       "<div class=\"lpIjsNNYrPWuoAjJabzAjjHLkXNccHajusPASEwk pvs-entity__sub-components\">\n",
       "<!-- --> <ul class=\"VcfWtteOjwrkCZnXQzzxBwAnJxBIDECsnqgUVQ\">\n",
       "<li class=\"IXhQpIGVagpuinnAtVdgNovRuikpqtYvmu\">\n",
       "<div class=\"lpIjsNNYrPWuoAjJabzAjjHLkXNccHajusPASEwk\">\n",
       "<!-- --> <ul class=\"VcfWtteOjwrkCZnXQzzxBwAnJxBIDECsnqgUVQ\">\n",
       "<li class=\"pvs-list__item--with-top-padding IXhQpIGVagpuinnAtVdgNovRuikpqtYvmu\">\n",
       "<div class=\"mv1 display-flex align-items-center\">\n",
       "<a class=\"optional-action-target-wrapper display-flex link-without-hover-visited\" data-field=\"position_contextual_skills_see_details\" href=\"https://www.linkedin.com/in/chandrasiddhartha/overlay/urn:li:fsd_profilePosition:(ACoAAAG3a7gBh4TkZQgmn1o6DOjO4eXTctJtyeU,874407095)/skill-associations-details?profileUrn=urn%3Ali%3Afsd_profile%3AACoAAAG3a7gBh4TkZQgmn1o6DOjO4eXTctJtyeU\" target=\"_self\">\n",
       "<div class=\"mr1 mv1\">\n",
       "<ul class=\"ivm-entity-pile display-flex align-items-center t-black\">\n",
       "<li class=\"ivm-entity-pile__img-item--stacked\">\n",
       "<div class=\"ivm-view-attr__img-wrapper\">\n",
       "<!-- -->\n",
       "<svg aria-hidden=\"true\" class=\"ivm-view-attr__icon ivm-view-attr__icon--icon\" data-supported-dps=\"16x16\" data-test-icon=\"skills-small\" height=\"16\" role=\"none\" viewbox=\"0 0 16 16\" width=\"16\" xmlns=\"http://www.w3.org/2000/svg\">\n",
       "<!-- -->\n",
       "<use height=\"16\" href=\"#skills-small\" width=\"16\"></use>\n",
       "</svg>\n",
       "</div>\n",
       "</li>\n",
       "</ul>\n",
       "</div>\n",
       "<div class=\"display-flex\">\n",
       "<div class=\"display-flex full-width\">\n",
       "<div class=\"hoverable-link-text display-flex align-items-center t-14 t-normal t-black\">\n",
       "<strong><!-- -->Git, Software Development and +5 skills<!-- --></strong>\n",
       "</div>\n",
       "</div>\n",
       "</div>\n",
       "</a>\n",
       "<!-- --> </div>\n",
       "</li>\n",
       "</ul>\n",
       "<!-- --> </div>\n",
       "</li>\n",
       "</ul>\n",
       "<!-- --> </div>\n",
       "</div>\n",
       "<!-- -->\n",
       "<!-- --> </div>"
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_exp(exp):\n",
    "\n",
    "    exp_dict = {}\n",
    "\n",
    "    name = exp.find('div', {'class': 'display-flex flex-wrap align-items-center full-height'}) # div containing name\n",
    "    name = name.find('span', {'class': 'visually-hidden'})  # span containing name\n",
    "    name = name.get_text().strip()  # get name from html like code\n",
    "\n",
    "    duration = exp.find('span', {'class': 't-14 t-normal'})  # div containing duration\n",
    "    duration = duration.find('span', {'class': 'visually-hidden'})  # span containing duration\n",
    "    duration = duration.get_text().strip() # get duration data\n",
    "\n",
    "    try:\n",
    "        image_tag = exp.find('img', {'class': 'ivm-view-attr__img--centered EntityPhoto-square-3 evi-image lazy-image ember-view'})\n",
    "        logo = image_tag.get('src')\n",
    "        exp_dict['logo'] = logo\n",
    "    except:\n",
    "        exp_dict['logo'] = \"\"\n",
    "        pass\n",
    "\n",
    "    exp_dict['company_name'] = name\n",
    "    exp_dict['duration'] = duration\n",
    "\n",
    "    designations = exp.find_all('div', {'class': 'fPLNkfiTqBJivqMiXLaRuObcmlUMZsDPkIAVk yCpXOOXwXcJnFOsCoYTsmMdAvLcplVbgNCBU'}) # find all designations of person within the company\n",
    "\n",
    "    item_list = []\n",
    "    for position in designations:\n",
    "        spans = position.find_all('span', {'class': 'visually-hidden'}) # gets the list of spans containing the required data\n",
    "\n",
    "        item_dict = {}\n",
    "        item_dict['designation'] = spans[0].get_text().strip()\n",
    "        item_dict['duration'] = spans[1].get_text().strip()\n",
    "        item_dict['location'] = spans[2].get_text().strip()\n",
    "\n",
    "        try:\n",
    "            item_dict['projects'] = spans[3].get_text().strip()  # if this span exists store the data\n",
    "        except:\n",
    "            item_dict['projects'] = \"\"\n",
    "\n",
    "        item_list.append(item_dict)\n",
    "\n",
    "\n",
    "    exp_dict['designations'] = item_list\n",
    "\n",
    "    return exp_dict\n",
    "\n",
    "item_list = []\n",
    "for exp in experience:  # do the above process for all companies \n",
    "    item_list.append(get_exp(exp)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['experience'] = item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'logo': 'https://media.licdn.com/dms/image/v2/C560BAQEKG5x_yU0olg/company-logo_100_100/company-logo_100_100/0/1631404661204/sp_tbi_logo?e=1741824000&v=beta&t=ZFFhVE31l1YSHL0heHc8LpK3k-WePk9IpOcwramALXU',\n",
       "  'company_name': 'Chief Executive Officer',\n",
       "  'duration': 'SP-TBI Â· Full-time',\n",
       "  'designations': []},\n",
       " {'logo': 'https://media.licdn.com/dms/image/v2/C510BAQHE1bLMZIcIxw/company-logo_100_100/company-logo_100_100/0/1630567177590/bhartiya_vidya_bhavans_sardar_patel_institute_of_technology_munshi_nagar_andheri_mumbai_logo?e=1741824000&v=beta&t=Z7IrGy9uI8Pib72_NBSInOhZqhWUh29joKh4S8XwpbM',\n",
       "  'company_name': 'Professor of Practice',\n",
       "  'duration': 'Bhartiya Vidya Bhavans Sardar Patel Institute of Technology Munshi Nagar Andheri Mumbai Â· Part-time',\n",
       "  'designations': []},\n",
       " {'logo': '',\n",
       "  'company_name': 'Founder',\n",
       "  'duration': 'Productivity stealth startup Â· Self-employed',\n",
       "  'designations': []},\n",
       " {'logo': 'https://media.licdn.com/dms/image/v2/D560BAQGC2UfHy7FIKw/company-logo_100_100/company-logo_100_100/0/1698971567557/nnext_co_logo?e=1741824000&v=beta&t=BrKsizSdrMhvzQ__NXBMZ2LNd_OsMfgaeG6Yg7tNlYg',\n",
       "  'company_name': 'Lead Machine Learning Engineer',\n",
       "  'duration': 'NNext Â· Full-time',\n",
       "  'designations': []},\n",
       " {'logo': 'https://media.licdn.com/dms/image/v2/D560BAQG1wEU0SSGUVQ/company-logo_100_100/company-logo_100_100/0/1720398339018/collective_i__logo?e=1741824000&v=beta&t=ZyxQTXPQRTDthP1SL50k7dM_codK9OZuD2x1YX0q-ng',\n",
       "  'company_name': 'Data Scientist',\n",
       "  'duration': 'Collective[i]',\n",
       "  'designations': []}]"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "profile_data['experience']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Education"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "for sec in sections:\n",
    "    if sec.find('div', {'id': 'education'}):\n",
    "        educations = sec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# educations.get_text().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "items = educations.find_all('div', {'class': 'gFJNglFOnyZmIAbxVkrWpQCmMhGSasZRfRtGlFg YcvguSXGGYgEmpWJOhQrhmNocNiIvvDjETE bAMoJMoZyFCvvmHkHNQEBnMuJTWUocrss'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_edu(item):\n",
    "    item_dict = {}\n",
    "    spans = item.find_all('span', {'class': 'visually-hidden'})\n",
    "\n",
    "    item_dict['college'] = spans[0].get_text().strip()\n",
    "    item_dict['degree'] = spans[1].get_text().strip()\n",
    "    item_dict['duration'] = spans[2].get_text().strip()\n",
    "    item_dict['project'] = spans[3].get_text().strip()\n",
    "\n",
    "    return item_dict\n",
    "\n",
    "item_list = []\n",
    "for item in items:\n",
    "    item_list.append(get_edu(item))\n",
    "\n",
    "profile_data['education'] = item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "# profile_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Licenses & certifications"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.ID, \"navigation-index-see-all-licenses-and-certifications\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "soup = soup.find('section', {'class': 'artdeco-card pb3'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = soup.find_all('div', {'class': 'gFJNglFOnyZmIAbxVkrWpQCmMhGSasZRfRtGlFg YcvguSXGGYgEmpWJOhQrhmNocNiIvvDjETE bAMoJMoZyFCvvmHkHNQEBnMuJTWUocrss'})\n",
    "\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = items[0]\n",
    "\n",
    "def get_license(item):\n",
    "    spans = item.find_all('span', {'class': 'visually-hidden'})\n",
    "\n",
    "    item_dict = {}\n",
    "    item_dict['name'] = spans[0].get_text().strip()\n",
    "    item_dict['institute'] = spans[1].get_text().strip()\n",
    "    item_dict['issued_date'] = spans[2].get_text().strip()\n",
    "\n",
    "    return item_dict\n",
    "\n",
    "item_list = []\n",
    "for item in items:\n",
    "    item_list.append(get_license(item))\n",
    "\n",
    "profile_data['licenses'] = item_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()\n",
    "# profile_data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.ID, \"navigation-index-see-all-projects\").click() \n",
    "# click to see all projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "soup = soup.find('section', {'class': 'artdeco-card pb3'}) # gets the section containing all projects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 145,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = soup.find_all('div', {'class': 'fPLNkfiTqBJivqMiXLaRuObcmlUMZsDPkIAVk SeRILEEOfWLelfcuceiLywOjAamlMoEkmnTdFk itGgYIXPpfAaqNrUDXHQVkGSUXMzldwQtdzM'})\n",
    "# get all project divs in a list\n",
    "\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = items[0]\n",
    "\n",
    "def get_project(item):\n",
    "    spans = item.find_all('span', {'class': 'visually-hidden'})\n",
    "\n",
    "    item_dict = {}\n",
    "    item_dict['project_name'] = spans[0].get_text().strip()\n",
    "    item_dict['duration'] = spans[1].get_text().strip()\n",
    "    item_dict['description'] = spans[2].get_text().strip()\n",
    "\n",
    "    return item_dict\n",
    "\n",
    "item_list = []\n",
    "for item in items:\n",
    "    item_list.append(get_project(item))\n",
    "\n",
    "profile_data['projects'] = item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ***Skills***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully clicked the 'Show All Skills' link.\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    view_all_skills_link = driver.find_element(\n",
    "        By.XPATH, \"//a[contains(@id, 'navigation-index-Show-all-') and contains(@id, '-skills')]\"\n",
    "    )\n",
    "    view_all_skills_link.click()\n",
    "    print(\"Successfully clicked the 'Show All Skills' link.\")\n",
    "except Exception as e:\n",
    "    print(\"Failed to find or click the link:\", e)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "soup = soup.find('section', {'class': 'artdeco-card pb3'}) # gets the section containing all skills"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "84"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "items = soup.find_all('div', {'class': 'fPLNkfiTqBJivqMiXLaRuObcmlUMZsDPkIAVk SeRILEEOfWLelfcuceiLywOjAamlMoEkmnTdFk itGgYIXPpfAaqNrUDXHQVkGSUXMzldwQtdzM'})\n",
    "# get all project divs in a list\n",
    "\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MLOps',\n",
       " 'Large Language Models (LLM)',\n",
       " 'PyTorch',\n",
       " 'Product Management',\n",
       " 'Cross-functional Collaborations',\n",
       " 'Critical Thinking',\n",
       " 'Predictive Modeling',\n",
       " 'Machine Learning',\n",
       " 'Artificial Intelligence (AI)',\n",
       " 'Deep Learning',\n",
       " 'Programming',\n",
       " 'Algorithms',\n",
       " 'Business Development',\n",
       " 'Business Strategy',\n",
       " 'Cloud Computing',\n",
       " 'Big Data',\n",
       " 'C',\n",
       " 'Matlab',\n",
       " 'Recurrent Neural Networks (RNN)',\n",
       " 'Amazon Web Services (AWS)',\n",
       " 'Python',\n",
       " 'TensorFlow',\n",
       " 'Keras',\n",
       " 'Google Cloud Platform (GCP)',\n",
       " 'Team Leadership',\n",
       " 'Team Management',\n",
       " 'Convolutional Neural Networks (CNN)',\n",
       " 'Scikit-Learn',\n",
       " 'Natural Language Processing (NLP)',\n",
       " 'Logistic Regression',\n",
       " 'Random Forest',\n",
       " 'Segmentation',\n",
       " 'Statistical Data Analysis',\n",
       " 'Statistical Analysis',\n",
       " 'Predictive Analysis',\n",
       " 'Regression Analysis',\n",
       " 'Data Analytics',\n",
       " 'Exploratory Analytics',\n",
       " 'Time series & Non Linear Modeling',\n",
       " 'Artificial Neural Networks',\n",
       " 'Neural Networks',\n",
       " 'Decision Trees',\n",
       " 'Support Vector Machine (SVM)',\n",
       " 'Data Analysis',\n",
       " 'Data Science',\n",
       " 'Matplotlib',\n",
       " 'Data Mining',\n",
       " 'NumPy',\n",
       " 'Pandas (Software)',\n",
       " 'SQL',\n",
       " 'MLOps',\n",
       " 'Large Language Models (LLM)',\n",
       " 'Product Management',\n",
       " 'Cross-functional Collaborations',\n",
       " 'Predictive Modeling',\n",
       " 'Machine Learning',\n",
       " 'Artificial Intelligence (AI)',\n",
       " 'Deep Learning',\n",
       " 'Programming',\n",
       " 'Algorithms',\n",
       " 'Business Development',\n",
       " 'Business Strategy',\n",
       " 'Cloud Computing',\n",
       " 'Big Data',\n",
       " 'Convolutional Neural Networks (CNN)',\n",
       " 'Scikit-Learn',\n",
       " 'Natural Language Processing (NLP)',\n",
       " 'Logistic Regression',\n",
       " 'Random Forest',\n",
       " 'Segmentation',\n",
       " 'PyTorch',\n",
       " 'C',\n",
       " 'Matlab',\n",
       " 'Recurrent Neural Networks (RNN)',\n",
       " 'Amazon Web Services (AWS)',\n",
       " 'Python',\n",
       " 'TensorFlow',\n",
       " 'Keras',\n",
       " 'Google Cloud Platform (GCP)',\n",
       " 'Pandas (Software)',\n",
       " 'SQL',\n",
       " 'Critical Thinking',\n",
       " 'Team Leadership',\n",
       " 'Team Management']"
      ]
     },
     "execution_count": 157,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_skills(item):\n",
    "    spans = item.find_all('span', {'class': 'visually-hidden'})\n",
    "    skill = spans[0].get_text().strip()\n",
    "    return skill\n",
    "\n",
    "item_list = []\n",
    "for item in items:\n",
    "    item_list.append(get_skills(item))\n",
    "\n",
    "item_list\n",
    "\n",
    "#profile_data['projects'] = item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All Courses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.ID, \"navigation-index-see-all-courses\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "18"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "soup = soup.find('section', {'class': 'artdeco-card pb3'})\n",
    "\n",
    "items = soup.find_all('div', {'class': 'gFJNglFOnyZmIAbxVkrWpQCmMhGSasZRfRtGlFg YcvguSXGGYgEmpWJOhQrhmNocNiIvvDjETE bAMoJMoZyFCvvmHkHNQEBnMuJTWUocrss'})\n",
    "\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "item = items[0]\n",
    "\n",
    "def get_course(item):\n",
    "    spans = item.find_all('span', {'class': 'visually-hidden'})\n",
    "\n",
    "    item_dict = {}\n",
    "    item_dict['course_name'] = spans[0].get_text().strip()\n",
    "    try:\n",
    "        item_dict['associated_with'] = spans[1].get_text().strip()\n",
    "    except:\n",
    "        item_dict['associated_with'] = \"\"\n",
    "\n",
    "    return item_dict\n",
    "\n",
    "item_list = []\n",
    "for item in items:\n",
    "    item_list.append(get_course(item))\n",
    "\n",
    "profile_data['courses'] = item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Honors & awards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.find_element(By.ID, \"navigation-index-see-all-honorsandawards\").click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "page_source = driver.page_source\n",
    "soup = BeautifulSoup(page_source, 'lxml')\n",
    "\n",
    "soup = soup.find('section', {'class': 'artdeco-card pb3'})\n",
    "\n",
    "items = soup.find_all('span', {'class': 'visually-hidden'})\n",
    "\n",
    "len(items)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "item_list = []\n",
    "for item in items:\n",
    "    item_list.append(item.get_text().strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "profile_data['honors_and_awards'] = item_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "with open('data/profile_data_tutorial.json', 'w') as f:\n",
    "    json.dump(profile_data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.back()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### pfp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "driver.get('https://www.linkedin.com/in/chandrasiddhartha/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "page_source = driver.page_source  # gets all the html code\n",
    "soup = BeautifulSoup(page_source, 'lxml') # parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_div = soup.find('div', {'class': 'ph5 pb5'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tag = image_div.find('img', {'class' : 'gYwGeQHVKFihyyWibCvmHZFDQZfKneaBo pv-top-card-profile-picture__image--show evi-image ember-view'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "pfp_uri = image_tag.get('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://media.licdn.com/dms/image/v2/D4D03AQFWg2jU8MfSag/profile-displayphoto-shrink_400_400/profile-displayphoto-shrink_400_400/0/1681301452770?e=1739404800&v=beta&t=wpJxy4ufWj-oYvDg1EIyB2S0WWSp0n2QGdet5rMe_l0'"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pfp_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_tag = soup.find('img', {'id': \"profile-background-image-target-image\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [],
   "source": [
    "banner_uri = image_tag.get('src')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'https://media.licdn.com/dms/image/v2/D4D16AQGvNQz8YAvH9Q/profile-displaybackgroundimage-shrink_350_1400/profile-displaybackgroundimage-shrink_350_1400/0/1678084310146?e=1739404800&v=beta&t=X24wkVHXPVoXUVTF0lGjjPBLFA8m0oYIif9DWOuPDvg'"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "banner_uri"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Companies logos top to bottom"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "class = ivm-view-attr__img--centered EntityPhoto-square-3   evi-image lazy-image ember-view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sections = soup.find_all('section', {'class': 'artdeco-card pv-profile-card break-words mt2'})  # get all the sections\n",
    "\n",
    "for sec in sections:\n",
    "    if sec.find('div', {'id': 'experience'}):  # find the experience section\n",
    "        experience = sec\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 241,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'aryaniscooked@gmail.com'"
      ]
     },
     "execution_count": 242,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.environ['EMAIL']"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py310",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
